{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e116d56-8d7c-44d8-a443-d5ec67bb2d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "zoo = fetch_ucirepo(id=111) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "x = zoo.data.features \n",
    "y = zoo.data.targets \n",
    "  \n",
    "# metadata \n",
    "#print(zoo.metadata) \n",
    "  \n",
    "# variable information \n",
    "#print(zoo.variables) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c8faa44-4492-47a6-b044-bd13a742a36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 0.1273 - loss: 2.5468 - val_accuracy: 0.0952 - val_loss: 2.8985\n",
      "Epoch 2/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1430 - loss: 2.4993 - val_accuracy: 0.0952 - val_loss: 2.8584\n",
      "Epoch 3/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1156 - loss: 2.5237 - val_accuracy: 0.0952 - val_loss: 2.8201\n",
      "Epoch 4/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1352 - loss: 2.4405 - val_accuracy: 0.0952 - val_loss: 2.7829\n",
      "Epoch 5/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1234 - loss: 2.4558 - val_accuracy: 0.0952 - val_loss: 2.7450\n",
      "Epoch 6/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1664 - loss: 2.3070 - val_accuracy: 0.0952 - val_loss: 2.7085\n",
      "Epoch 7/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1117 - loss: 2.4116 - val_accuracy: 0.0952 - val_loss: 2.6716\n",
      "Epoch 8/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1234 - loss: 2.3341 - val_accuracy: 0.0952 - val_loss: 2.6360\n",
      "Epoch 9/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1430 - loss: 2.2444 - val_accuracy: 0.0952 - val_loss: 2.6012\n",
      "Epoch 10/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.1352 - loss: 2.2843 - val_accuracy: 0.0952 - val_loss: 2.5659\n",
      "Epoch 11/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1258 - loss: 2.2509 - val_accuracy: 0.0952 - val_loss: 2.5316\n",
      "Epoch 12/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1570 - loss: 2.1835 - val_accuracy: 0.0952 - val_loss: 2.4983\n",
      "Epoch 13/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.1570 - loss: 2.2157 - val_accuracy: 0.0952 - val_loss: 2.4652\n",
      "Epoch 14/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.1398 - loss: 2.1906 - val_accuracy: 0.0952 - val_loss: 2.4333\n",
      "Epoch 15/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1852 - loss: 2.1339 - val_accuracy: 0.0952 - val_loss: 2.4019\n",
      "Epoch 16/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2031 - loss: 2.0896 - val_accuracy: 0.0952 - val_loss: 2.3718\n",
      "Epoch 17/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2133 - loss: 2.0967 - val_accuracy: 0.0952 - val_loss: 2.3419\n",
      "Epoch 18/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2016 - loss: 2.0838 - val_accuracy: 0.0952 - val_loss: 2.3126\n",
      "Epoch 19/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1859 - loss: 2.0952 - val_accuracy: 0.0952 - val_loss: 2.2841\n",
      "Epoch 20/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2211 - loss: 2.0104 - val_accuracy: 0.0952 - val_loss: 2.2568\n",
      "Epoch 21/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.2055 - loss: 2.0362 - val_accuracy: 0.1905 - val_loss: 2.2296\n",
      "Epoch 22/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2258 - loss: 2.0143 - val_accuracy: 0.1905 - val_loss: 2.2026\n",
      "Epoch 23/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.2219 - loss: 1.9928 - val_accuracy: 0.1905 - val_loss: 2.1769\n",
      "Epoch 24/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2508 - loss: 1.9825 - val_accuracy: 0.1905 - val_loss: 2.1519\n",
      "Epoch 25/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2820 - loss: 1.9434 - val_accuracy: 0.1905 - val_loss: 2.1275\n",
      "Epoch 26/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3180 - loss: 1.9185 - val_accuracy: 0.1429 - val_loss: 2.1034\n",
      "Epoch 27/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3031 - loss: 1.9369 - val_accuracy: 0.1429 - val_loss: 2.0791\n",
      "Epoch 28/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3148 - loss: 1.9031 - val_accuracy: 0.1429 - val_loss: 2.0556\n",
      "Epoch 29/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3461 - loss: 1.8720 - val_accuracy: 0.1429 - val_loss: 2.0328\n",
      "Epoch 30/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3109 - loss: 1.8765 - val_accuracy: 0.1429 - val_loss: 2.0099\n",
      "Epoch 31/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3461 - loss: 1.8314 - val_accuracy: 0.1429 - val_loss: 1.9877\n",
      "Epoch 32/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3422 - loss: 1.8165 - val_accuracy: 0.1429 - val_loss: 1.9656\n",
      "Epoch 33/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3422 - loss: 1.8009 - val_accuracy: 0.1429 - val_loss: 1.9436\n",
      "Epoch 34/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3227 - loss: 1.8018 - val_accuracy: 0.1429 - val_loss: 1.9220\n",
      "Epoch 35/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.3031 - loss: 1.8043 - val_accuracy: 0.1429 - val_loss: 1.9006\n",
      "Epoch 36/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.3305 - loss: 1.7806 - val_accuracy: 0.1429 - val_loss: 1.8801\n",
      "Epoch 37/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.3930 - loss: 1.7302 - val_accuracy: 0.1429 - val_loss: 1.8614\n",
      "Epoch 38/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3031 - loss: 1.7708 - val_accuracy: 0.1429 - val_loss: 1.8421\n",
      "Epoch 39/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3305 - loss: 1.7349 - val_accuracy: 0.1429 - val_loss: 1.8239\n",
      "Epoch 40/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3344 - loss: 1.7370 - val_accuracy: 0.1429 - val_loss: 1.8056\n",
      "Epoch 41/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3461 - loss: 1.6989 - val_accuracy: 0.1429 - val_loss: 1.7876\n",
      "Epoch 42/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2992 - loss: 1.7069 - val_accuracy: 0.1429 - val_loss: 1.7698\n",
      "Epoch 43/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3258 - loss: 1.7182 - val_accuracy: 0.1429 - val_loss: 1.7524\n",
      "Epoch 44/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3734 - loss: 1.6849 - val_accuracy: 0.1429 - val_loss: 1.7358\n",
      "Epoch 45/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4187 - loss: 1.6439 - val_accuracy: 0.4286 - val_loss: 1.7194\n",
      "Epoch 46/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4672 - loss: 1.6785 - val_accuracy: 0.4286 - val_loss: 1.7028\n",
      "Epoch 47/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5047 - loss: 1.6465 - val_accuracy: 0.5238 - val_loss: 1.6874\n",
      "Epoch 48/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6258 - loss: 1.6060 - val_accuracy: 0.5238 - val_loss: 1.6722\n",
      "Epoch 49/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5945 - loss: 1.6267 - val_accuracy: 0.5714 - val_loss: 1.6565\n",
      "Epoch 50/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5617 - loss: 1.6229 - val_accuracy: 0.5714 - val_loss: 1.6421\n",
      "Epoch 51/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5773 - loss: 1.6043 - val_accuracy: 0.6190 - val_loss: 1.6287\n",
      "Epoch 52/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5773 - loss: 1.6137 - val_accuracy: 0.6190 - val_loss: 1.6151\n",
      "Epoch 53/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6227 - loss: 1.5738 - val_accuracy: 0.6190 - val_loss: 1.6020\n",
      "Epoch 54/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6406 - loss: 1.5675 - val_accuracy: 0.6190 - val_loss: 1.5892\n",
      "Epoch 55/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6328 - loss: 1.5687 - val_accuracy: 0.6667 - val_loss: 1.5768\n",
      "Epoch 56/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6258 - loss: 1.5598 - val_accuracy: 0.6190 - val_loss: 1.5648\n",
      "Epoch 57/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6492 - loss: 1.5558 - val_accuracy: 0.6667 - val_loss: 1.5531\n",
      "Epoch 58/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6750 - loss: 1.5125 - val_accuracy: 0.7143 - val_loss: 1.5418\n",
      "Epoch 59/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6852 - loss: 1.5234 - val_accuracy: 0.7143 - val_loss: 1.5308\n",
      "Epoch 60/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6500 - loss: 1.5506 - val_accuracy: 0.7143 - val_loss: 1.5203\n",
      "Epoch 61/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6539 - loss: 1.5262 - val_accuracy: 0.7143 - val_loss: 1.5093\n",
      "Epoch 62/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6930 - loss: 1.4937 - val_accuracy: 0.6667 - val_loss: 1.4987\n",
      "Epoch 63/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6297 - loss: 1.5217 - val_accuracy: 0.7143 - val_loss: 1.4892\n",
      "Epoch 64/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6359 - loss: 1.5282 - val_accuracy: 0.7143 - val_loss: 1.4809\n",
      "Epoch 65/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7023 - loss: 1.4617 - val_accuracy: 0.7143 - val_loss: 1.4725\n",
      "Epoch 66/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6320 - loss: 1.5017 - val_accuracy: 0.7143 - val_loss: 1.4641\n",
      "Epoch 67/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6789 - loss: 1.4818 - val_accuracy: 0.7143 - val_loss: 1.4551\n",
      "Epoch 68/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6711 - loss: 1.4567 - val_accuracy: 0.7143 - val_loss: 1.4465\n",
      "Epoch 69/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6711 - loss: 1.4490 - val_accuracy: 0.7143 - val_loss: 1.4376\n",
      "Epoch 70/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6828 - loss: 1.4350 - val_accuracy: 0.7143 - val_loss: 1.4284\n",
      "Epoch 71/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6789 - loss: 1.4183 - val_accuracy: 0.7143 - val_loss: 1.4197\n",
      "Epoch 72/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6852 - loss: 1.4201 - val_accuracy: 0.7143 - val_loss: 1.4118\n",
      "Epoch 73/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6734 - loss: 1.4461 - val_accuracy: 0.7143 - val_loss: 1.4033\n",
      "Epoch 74/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6500 - loss: 1.4404 - val_accuracy: 0.7143 - val_loss: 1.3949\n",
      "Epoch 75/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6734 - loss: 1.4382 - val_accuracy: 0.7143 - val_loss: 1.3866\n",
      "Epoch 76/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6578 - loss: 1.4361 - val_accuracy: 0.7143 - val_loss: 1.3790\n",
      "Epoch 77/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6773 - loss: 1.4017 - val_accuracy: 0.7143 - val_loss: 1.3711\n",
      "Epoch 78/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6422 - loss: 1.4325 - val_accuracy: 0.7143 - val_loss: 1.3636\n",
      "Epoch 79/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7008 - loss: 1.3613 - val_accuracy: 0.7143 - val_loss: 1.3563\n",
      "Epoch 80/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6578 - loss: 1.4169 - val_accuracy: 0.7143 - val_loss: 1.3492\n",
      "Epoch 81/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7008 - loss: 1.3368 - val_accuracy: 0.7143 - val_loss: 1.3416\n",
      "Epoch 82/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6539 - loss: 1.3901 - val_accuracy: 0.7143 - val_loss: 1.3337\n",
      "Epoch 83/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6812 - loss: 1.3772 - val_accuracy: 0.7143 - val_loss: 1.3258\n",
      "Epoch 84/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6695 - loss: 1.3570 - val_accuracy: 0.7143 - val_loss: 1.3180\n",
      "Epoch 85/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6852 - loss: 1.3254 - val_accuracy: 0.7143 - val_loss: 1.3109\n",
      "Epoch 86/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6500 - loss: 1.3704 - val_accuracy: 0.7143 - val_loss: 1.3038\n",
      "Epoch 87/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7320 - loss: 1.2833 - val_accuracy: 0.7143 - val_loss: 1.2968\n",
      "Epoch 88/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6539 - loss: 1.3363 - val_accuracy: 0.7143 - val_loss: 1.2902\n",
      "Epoch 89/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7008 - loss: 1.3173 - val_accuracy: 0.7143 - val_loss: 1.2834\n",
      "Epoch 90/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6773 - loss: 1.3179 - val_accuracy: 0.7143 - val_loss: 1.2769\n",
      "Epoch 91/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6891 - loss: 1.2986 - val_accuracy: 0.7143 - val_loss: 1.2700\n",
      "Epoch 92/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6891 - loss: 1.2990 - val_accuracy: 0.7143 - val_loss: 1.2638\n",
      "Epoch 93/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6852 - loss: 1.2998 - val_accuracy: 0.7143 - val_loss: 1.2573\n",
      "Epoch 94/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6773 - loss: 1.3139 - val_accuracy: 0.7143 - val_loss: 1.2507\n",
      "Epoch 95/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6578 - loss: 1.2970 - val_accuracy: 0.7143 - val_loss: 1.2443\n",
      "Epoch 96/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6969 - loss: 1.2548 - val_accuracy: 0.7143 - val_loss: 1.2379\n",
      "Epoch 97/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6852 - loss: 1.2543 - val_accuracy: 0.7143 - val_loss: 1.2317\n",
      "Epoch 98/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6930 - loss: 1.2541 - val_accuracy: 0.7143 - val_loss: 1.2253\n",
      "Epoch 99/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6734 - loss: 1.2657 - val_accuracy: 0.7143 - val_loss: 1.2195\n",
      "Epoch 100/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6992 - loss: 1.2332 - val_accuracy: 0.7143 - val_loss: 1.2139\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7143 - loss: 1.2139\n",
      "Precisión en el conjunto de prueba: 0.7142857313156128\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Datos de entrada\n",
    "features = x.values\n",
    "\n",
    "# Target\n",
    "target = y.values\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir la arquitectura de la red neuronal\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(16,)),  # Capa de entrada con 16 neuronas\n",
    "    tf.keras.layers.Dense(64, activation='sigmoid'),  # Capa oculta con 64 neuronas y función de activación ReLU\n",
    "    tf.keras.layers.Dense(7, activation='softmax')  # Capa de salida con 1 neurona y función de activación Softmax\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluar el modelo\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Precisión en el conjunto de prueba:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "5bc81c57-0df4-462c-aca0-977d0ce90390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f1278a2-37a7-4836-b953-c9385509b86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Función de activación sigmoide\n",
    "def sigmoid(x):\n",
    "    x = np.clip(x, -500, 500)\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Derivada de la función de activación sigmoide\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Clase PerceptronMulticapa\n",
    "class PerceptronMulticapa:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # Inicialización de pesos y sesgos\n",
    "        self.weights_input_hidden = np.random.rand(input_size, hidden_size)\n",
    "        self.weights_hidden_output = np.random.rand(hidden_size, output_size)\n",
    "        self.bias_hidden = np.random.rand(1, hidden_size)\n",
    "        self.bias_output = np.random.rand(1, output_size)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # Propagación hacia adelante\n",
    "        self.hidden_input = np.dot(X, self.weights_input_hidden) + self.bias_hidden\n",
    "        self.hidden_output = sigmoid(self.hidden_input)\n",
    "        self.output = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_output\n",
    "        return self.output\n",
    "        \n",
    "    def backward(self, X, y, output, learning_rate):\n",
    "        # Retropropagación\n",
    "        error = y - output\n",
    "        d_output = error\n",
    "        d_hidden = np.dot(d_output, self.weights_hidden_output.T) * sigmoid_derivative(self.hidden_output)\n",
    "        \n",
    "        # Actualización de pesos y sesgos\n",
    "        self.weights_hidden_output += np.dot(self.hidden_output.T, d_output) * learning_rate\n",
    "        self.weights_input_hidden += np.dot(X.T, d_hidden) * learning_rate\n",
    "        self.bias_output += np.sum(d_output, axis=0, keepdims=True) * learning_rate\n",
    "        self.bias_hidden += np.sum(d_hidden, axis=0, keepdims=True) * learning_rate\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Obtener la salida del modelo para un conjunto de datos de entrada dado\n",
    "        return self.forward(X)\n",
    "    \n",
    "    def train(self, X, y, epochs, learning_rate,debug=False):\n",
    "        for epoch in range(epochs):\n",
    "            # Propagación hacia adelante\n",
    "            output = self.forward(X)\n",
    "            \n",
    "            # Retropropagación\n",
    "            self.backward(X, y, output, learning_rate)\n",
    "            \n",
    "            # Calcular la pérdida\n",
    "            loss = np.mean(np.square(y - output))\n",
    "            if debug and epoch % 100 == 0:\n",
    "                print(f'Epoch {epoch}, Loss: {loss:.4f}')\n",
    "\n",
    "zoo = fetch_ucirepo(id=111) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = zoo.data.features \n",
    "y = zoo.data.targets \n",
    "  \n",
    "# Normalizar los datos\n",
    "X = X / np.amax(X, axis=0)\n",
    "y = y / 7  # Normalizar los objetivos al rango [0, 1]\n",
    "\n",
    "#print(y_train)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n",
    "#print(y_train.values)\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "# Crear y entrenar el perceptrón multicapa\n",
    "input_size = 16#X_train.shape[1]\n",
    "hidden_size = 32\n",
    "output_size = 7\n",
    "\n",
    "perceptron = PerceptronMulticapa(input_size, hidden_size, output_size)\n",
    "perceptron.train(X_train, y_train, epochs=1000, learning_rate=0.01)\n",
    "predictions = perceptron.predict(X_test)\n",
    "#print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "807f09f7-0b4c-4383-984b-d63b4b48319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ec26e7d7-cd12-47bd-b7c1-02149fcf2b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  -  [35.]\n",
      "1  -  [14.]\n",
      "1  -  [28.]\n",
      "1  -  [14.]\n",
      "1  -  [7.]\n",
      "1  -  [7.]\n",
      "1  -  [28.]\n",
      "6  -  [42.]\n",
      "1  -  [7.]\n",
      "1  -  [28.]\n",
      "6  -  [49.]\n",
      "1  -  [7.]\n",
      "1  -  [7.]\n",
      "6  -  [49.]\n",
      "1  -  [7.]\n",
      "1  -  [14.]\n",
      "1  -  [21.]\n",
      "6  -  [42.]\n",
      "1  -  [7.]\n",
      "1  -  [7.]\n",
      "1  -  [14.]\n",
      "acc:  0.0\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for itr,pred in enumerate(predictions):\n",
    "    if(np.argmax(pred)+1 == y_test[itr]*7):\n",
    "        total += 1\n",
    "    #print(np.argmax(pred)+1,' - ',y_test[itr]*7)\n",
    "print('acc: ',total/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a982e86-2d9a-4a5d-b515-403544c4c927",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test = y_test * 7\n",
    "y_test \n",
    "#y_test.to_csv('y_test.csv', index=True)\n",
    "np.savetxt('y_test.csv', y_test, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "212634a5-ba75-4a71-a679-3d8ed5348d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.000000000000000000e+00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [2.0, 4.0, 2.0, 1.0, 1.0, 4.0, 6.0, 1.0, 4.0, 7.0, 1.0, 1.0, 7.0, 1.0, 2.0, 3.0, 6.0, 1.0, 1.0, 2.0]"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('y_train.csv',index_col=0)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
